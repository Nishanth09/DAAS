version: '3'

networks:
  daas:
    external: false
    name: daas

services:
  server:
    build:
      context: ./server
      dockerfile: ./Dockerfile
    image: server:node
    container_name: node_container
    ports:
      - "5001:5001"
    networks:
      - daas
    volumes:
      - ./server:/295B/server
    
  client:
    build:
      context: ./client
      dockerfile: ./Dockerfile
    image: client:react
    container_name: react_container
    ports:
      - "3000:3000"
    networks:
      - daas
    volumes:
    - ./client:/295B/client
  cassandra:
    image: docker.io/bitnami/cassandra:latest
    user: root
    container_name: cassandra
    ports:
      # - '7000:7000'
      - '9042:9042'
    volumes:
      - ./cassandra/schema:/docker-entrypoint-initdb.d
      - 'cassandra_data:/bitnami'
    healthcheck:
      test: [ "CMD", "/opt/bitnami/cassandra/bin/cqlsh", "-u cassandra", "-p cassandra" ,"-e \"describe keyspaces\"" ]
      interval: 15s
      timeout: 10s
      retries: 10
    environment:
      - CASSANDRA_SEEDS=cassandra
      - CASSANDRA_PASSWORD_SEEDER=yes
      - CASSANDRA_PASSWORD=cassandra
    networks:
      - daas

    
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - type: volume
        source: zookeeper_vol
        target: /var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 200000000
      KAFKA_MAX_PARTITION_FETCH_BYTES: 200000000
      KAFKA_FETCH_MAX_BYTES: 200000000
      KAFKA_MAX_REQUEST_SIZE: 200000000
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 200000000
    volumes:
      - type: volume
        source: kafka_vol
        target: /var/lib/kafka/data

  spark-master:
    image: spark-master
    container_name: spark-master
    build:
      context: ./processingServer
      dockerfile: ./Dockerfile
      target: "spark-master"
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - hadoop-workspace:/opt/workspace
    networks:
      - daas

  spark-worker-1:
    image: spark-worker
    container_name: spark-worker-1
    build:
      context: ./processingServer
      dockerfile: ./Dockerfile
      target: "spark-worker"
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    ports:
      - 8081:8081
    volumes:
      - hadoop-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - daas

  processingServer:
    build:
      context: ./processingServer
      dockerfile: ./Dockerfile
      target: "flask-server"
    image: flaskserver
    container_name: flaskserver
    depends_on:
      - spark-master
    ports:
      - "5000:5000"
    networks:
      - daas
    volumes:
      - ./processingServer:/usr/bin/spark-3.1.2-bin-hadoop3.2/295B/processingServer

volumes:
  cassandra_data:
    driver: local
  kafka_vol:
  zookeeper_vol:
  hadoop-workspace:
    driver: local